{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tutorial A: Simple Regression with DNN.ipynb","provenance":[],"authorship_tag":"ABX9TyNnllqsTtSUQmfNpRW2K37/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IRrJ6T7eOOBk"},"source":["# Tutorial A: Simple Regression with DNN\n","\n","Adapted from: https://www.tensorflow.org/tutorials/keras/regression\n","\n","This tutorial helps you guide to work on a simple *regression* problem. The regression task will be done by a **deep neural network**.\n","\n","The dataset that is used is the Auto MPG dataset. Given several features of a vehicle, we plan to predict how many MPGs of fuel the vehicle consumes on average."]},{"cell_type":"markdown","metadata":{"id":"o0r1VeyVPEkB"},"source":["## 1. Prepare Libraries"]},{"cell_type":"code","metadata":{"id":"d9-SCcNukIvy"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","# Make NumPy printouts easier to read.\n","np.set_printoptions(precision=3, suppress=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN5GRnNIOtM6"},"source":["import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.utils import plot_model\n","\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0vAR5SYGPLIb"},"source":["We can also view what GPU resources that we can work with using this kernel. This command is specific for NVIDIA GPUs only."]},{"cell_type":"code","metadata":{"id":"tD3w7ED0PVvq"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mGXhKJPPPfyu"},"source":["The GPU that is installed in the DGX-A100 system (NVIDIA A100) has **Multi-Instance GPU (MIG)** support, where one GPU can be divided into several seperate instances. The resources that you see on the second table is the GPU instance that is assigned for this specific Pod.\n","\n","More information on NVIDIA's MIG: https://blogs.nvidia.com/blog/2020/05/14/multi-instance-gpus/"]},{"cell_type":"markdown","metadata":{"id":"nPVC7ObkPYa8"},"source":["## 2. Retrieve The Dataset\n","\n","For this task, we will use The Auto MPG dataset provided on UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/)\n","\n","The dataset consists of 8 columns, which are:\n","- **MPG (Miles per gallon)**: Measures the fuel efficiency of a vehicle.\n","- **Cylinders**: How many cylinders that the vehicle's engine have\n","- **Displacement**: Measures the size of the engine.\n","- **Horsepower**: Measures the power output of the vehicle.\n","- **Weight**: The total weight of the vehicle.\n","- **Acceleration**: How many seconds the vehicle needed to reach 60 mph from 0.\n","- **Model Year**: Defines the year when the vehicle was made.\n","- **Origin**: Defines which area the vehicle was originally manufactured."]},{"cell_type":"code","metadata":{"id":"Xc5411oIPXYt"},"source":["url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n","column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n","                'Acceleration', 'Model Year', 'Origin']\n","\n","raw_dataset = pd.read_csv(url, names=column_names,\n","                          na_values='?', comment='\\t',\n","                          sep=' ', skipinitialspace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99EzMjzGPcEj"},"source":["dataset = raw_dataset.copy()\n","dataset.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6R7BrMxJQpc_"},"source":["### Cleaning The Data\n","\n","Most of the data is already clean enough, except for one specific column, which is horsepower. There are several ways to clean the data. For this case, we will just ignore the vehicles without any horsepower information completely."]},{"cell_type":"code","metadata":{"id":"hJ_ZFIefQmgV"},"source":["dataset.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWf0V0bPQtaG"},"source":["dataset = dataset.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8_O2qsBhQzQt"},"source":["### Do One-Hot Encoding for Column \"Origin\"\n","\n","We will do a one-hot encoding for the column origin, due to its categorical attribute."]},{"cell_type":"code","metadata":{"id":"RbahG65FQ5Qa"},"source":["dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n","dataset = pd.get_dummies(dataset, columns=['Origin'], prefix='', prefix_sep='')\n","dataset.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ORgNlH53RCVi"},"source":["### Split The Data"]},{"cell_type":"code","metadata":{"id":"EkZvemSzQ8m5"},"source":["train_dataset = dataset.sample(frac=0.8, random_state=0)\n","test_dataset = dataset.drop(train_dataset.index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NtslOEaXRH_a"},"source":["## 3. Exploratory Data Analysis"]},{"cell_type":"code","metadata":{"id":"nnhu21H2RKog"},"source":["sns.pairplot(train_dataset[['MPG', 'Cylinders', 'Displacement', 'Weight']], diag_kind='kde')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"29EqWujzRSqi"},"source":["train_dataset.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j88U8EDM0QrE"},"source":["### Seperate Features ($X$) and Labels ($y$)\n"]},{"cell_type":"code","metadata":{"id":"YroLJhd6RSxQ"},"source":["train_features = train_dataset.copy()\n","test_features = test_dataset.copy()\n","\n","train_labels = train_features.pop('MPG')\n","test_labels = test_features.pop('MPG')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Np4_3cSR0vlF"},"source":["## 4. Simple Regression with Deep Neural Network\n","\n","Now we will begin the modeling process using a deep neural network."]},{"cell_type":"markdown","metadata":{"id":"f7XsbjKK0yFc"},"source":["### Add Normalization\n","\n","Before going any further, it is recommended to apply a normalization for all the columns to make sure all the features are equally scaled."]},{"cell_type":"code","metadata":{"id":"1ZMDhuID0xYB"},"source":["normalizer = tf.keras.layers.Normalization(axis=-1)\n","normalizer.adapt(np.array(train_features))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qf6Ov7r456VB"},"source":["For the model, we will use a normalization layer, then added with 3 hidden dense layers and one output layer."]},{"cell_type":"code","metadata":{"id":"hVx6cdQz1FjG"},"source":["def build_and_compile_model(norm):\n","  model = keras.Sequential([\n","      norm,\n","      layers.Dense(64, activation='relu'),\n","      layers.Dense(64, activation='relu'),\n","      layers.Dense(64, activation='relu'),\n","      layers.Dense(1)  # output layer\n","  ])\n","\n","  model.compile(loss='mean_absolute_error',\n","                optimizer=tf.keras.optimizers.Adam(0.001))\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NNnvKRq11Whh"},"source":["dnn_model = build_and_compile_model(normalizer)\n","dnn_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKNhWaSH1YSM"},"source":["plot_model(dnn_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5o7QNOTa6MJ2"},"source":["We will start the training process with 100 epochs. Feel free to experiment with different hyperparameter values."]},{"cell_type":"code","metadata":{"id":"Cd6KK7GY1dYk"},"source":["%%time\n","history = dnn_model.fit(\n","    train_features,\n","    train_labels,\n","    validation_split=0.2,\n","    verbose=0, epochs=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_1XVCEL1jtc"},"source":["def plot_loss(history):\n","  plt.plot(history.history['loss'], label='loss')\n","  plt.plot(history.history['val_loss'], label='val_loss')\n","  plt.ylim([0, 10])\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Error [MPG]')\n","  plt.legend()\n","  plt.grid(True)\n","\n","plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kv2FGQ6Z6ceF"},"source":["## Additional: View GPU Usage"]},{"cell_type":"code","metadata":{"id":"X27kqIy92AOo"},"source":["if tf.config.list_physical_devices('GPU'):\n","  print(tf.config.experimental.get_memory_info('GPU:0'))"],"execution_count":null,"outputs":[]}]}